{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cfc8d7e9cacffb065dc3a60da174e71b9696ea8b"
   },
   "source": [
    "For the general context, see  also:\n",
    "\n",
    "* A deepsense.ai blog post [Keras vs. PyTorch - Alien vs. Predator recognition with transfer learning](https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning) in which we compare and contrast Keras and PyTorch approaches.\n",
    "* Repo with code: [github.com/deepsense-ai/Keras-PyTorch-AvP-transfer-learning](https://github.com/deepsense-ai/Keras-PyTorch-AvP-transfer-learning).\n",
    "* Free event: [upcoming webinar (10 Oct 2018)](https://www.crowdcast.io/e/KerasVersusPyTorch/register), in which we walk trough the code (and you will be able to ask questions).\n",
    "\n",
    "### 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "96187e5bb4a84c3ddcfae7928fa4bf9032b1a1fb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "fa58369ae6b436d90bdd8d7955acb4d2f257e567"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras import Model, layers\n",
    "from keras.models import load_model, model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "8d58287c1b455eb2ed0c22b7bdd8f7371555a049"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__  # should be 2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "5bfd3f273fc6f1598770cd82587a1d49b8129ce0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__  # should be 1.10.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6c7d71cebd676a78730b2ea3056fec9304b5f8ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "PIL.__version__  # should be 5.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c3e767c150f478a0e59688d44f8ffe7018156906"
   },
   "outputs": [],
   "source": [
    "# path for Kaggle kernels\n",
    "input_path = \"./persons-cropped/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3fc35f7f812c9f1fb95db51b66084f965c7b243a"
   },
   "source": [
    "### 2. Create Keras data generators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "5815de285f4e0465e391c80b3f80bb9a071f7bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3803 images belonging to 140 classes.\n",
      "Found 708 images belonging to 130 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=10,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    input_path + 'train',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    target_size=(224,224))\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    input_path + 'test',\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    target_size=(224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a25efd644b40165eddbb1c488fe15f536d3a6c7"
   },
   "source": [
    "### 3. Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "96a29a0b271b063800b8327db17d2c5a5c0371c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dzeri/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzeri/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "conv_base = ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet')\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "e3c984a85ded2fc8a66ccef7cb509aa22194e8f6"
   },
   "outputs": [],
   "source": [
    "x = conv_base.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x) \n",
    "predictions = layers.Dense(2, activation='softmax')(x)\n",
    "model = Model(conv_base.input, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "45d0f2b9057da01918f6a797ed42f664978ceaa1"
   },
   "source": [
    "Note:  there was an error with the above on Kaggle (even though it works on my computer, same versions of Keras and TF):\n",
    "\n",
    "> AttributeError: 'Node' object has no attribute 'output_masks'\n",
    "\n",
    "See [this issue](https://github.com/keras-team/keras/issues/10907).\n",
    "After reinstalling TensorFlow in Kaggle (packages -> tensorflow), no error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzeri/.local/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "our_layer (Dense)            (None, 140)               14049420  \n",
      "=================================================================\n",
      "Total params: 37,637,132\n",
      "Trainable params: 14,049,420\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(140, activation='softmax', name='our_layer'))\n",
    "model.layers[0].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "fd9067b2ab21bba71215b07a7009ddf4774ed789"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb7610241dbb3290e716821ff6ede7d4ca298526"
   },
   "source": [
    "### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "c807eba33564428e93c8e025bf160fc58401554c",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8a3fb663b98b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit_generator(generator=train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m347\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# added in Kaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m  \u001b[0;31m# added in Kaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=347 // 32,  # added in Kaggle\n",
    "                              epochs=3,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=10  # added in Kaggle\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4dbd038f85cc49336779b71121b2db4774c26255"
   },
   "source": [
    "### 5. Save and load the model\n",
    "\n",
    "Note: this is for demonstration. You don't need to to so, if you intend to run predictions within this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0fcabc85be10e58321c10e4c6aa9e69de3165b0"
   },
   "outputs": [],
   "source": [
    "!mkdir models\n",
    "!mkdir models/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ec724cd6603523b8d333fbe788b04b2cd35957c"
   },
   "source": [
    "#### A. Architecture and weights in HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c64db0a96b7bfcf587de6d1d6fae28e79bb7f6d"
   },
   "outputs": [],
   "source": [
    "# save\n",
    "model.save('models/keras/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2704e0627cf5889aa2d0e8f866bd12e037cb20c0"
   },
   "outputs": [],
   "source": [
    "# load\n",
    "model = load_model('models/keras/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5dc8971ce3eeaeee04031abc3f1fd120933981bd"
   },
   "source": [
    "#### B. Architecture in JSON,  weights in HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dd2c336625d564768a3b4596d47a57715b3a0d5c"
   },
   "outputs": [],
   "source": [
    "# save\n",
    "model.save_weights('models/keras/weights.h5')\n",
    "with open('models/keras/architecture.json', 'w') as f:\n",
    "        f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e4b755c87531ace01a54d6b0c0a812cda88ae9c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load\n",
    "with open('models/keras/architecture.json') as f:\n",
    "    model = model_from_json(f.read())\n",
    "model.load_weights('models/keras/weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd7a19d48239bc92bec9120d7d2504d1f197e0e9"
   },
   "source": [
    "### 6. Make predictions on sample test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e93253594da98d568d7a8ab8648ecdf36ecad62a"
   },
   "outputs": [],
   "source": [
    "validation_img_paths = [\"validation/alien/11.jpg\",\n",
    "                        \"validation/alien/22.jpg\",\n",
    "                        \"validation/predator/33.jpg\"]\n",
    "img_list = [Image.open(input_path + img_path) for img_path in validation_img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56c46dc91b8aee4e934f9ef80ec4ee1c969f22af"
   },
   "outputs": [],
   "source": [
    "validation_batch = np.stack([preprocess_input(np.array(img.resize((224,224))))\n",
    "                             for img in img_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1673578792aea6a67adef6b3cf5af57995e3e95"
   },
   "outputs": [],
   "source": [
    "pred_probs = model.predict(validation_batch)\n",
    "pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8a22e5758d55d1757df9e5660ebb7928b14bc13"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))\n",
    "for i, img in enumerate(img_list):\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"{:.0f}% Alien, {:.0f}% Predator\".format(100*pred_probs[i,0],\n",
    "                                                            100*pred_probs[i,1]))\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9bc111d07c7831648d55e6343e984fef6fecb4a9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
